# MLPRegressor
# dataset: whole_dataset
# date: 2020-04-14T11_58_30.681597
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0005951915361345095, "batch_size": 1, "activation": "logistic", "learning_rate": "adaptive", "learning_rate_init": 0.054980020763198, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.8050419419933234, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	1.5944666023400929	1.5944666023400929	1.3987752878830721
2	4.339909528863095	4.339909528863095	2.6038438553370264
3	2.0070863838602437	2.0070863838602437	1.669935396657105
4	1.0509118507777944	1.0509118507777944	1.182568580371719
5	0.9787791262384908	0.9787791262384908	1.09122132119234
6	0.9925789585193103	0.9925789585193103	1.0870136675564228
7	1.1371472958060405	1.1371472958060405	1.2144011804800183
8	0.7916755992755286	0.7916755992755286	0.9718910636044137
9	0.8768601993001983	0.8768601993001983	1.0670300493461904
10	0.8654702557650049	0.8654702557650049	1.0408484934551974
11	0.7354685455688904	0.7354685455688904	0.9354852030108675
12	0.7364735449955786	0.7364735449955786	0.9334585183524514
13	0.7416371425492896	0.7416371425492896	0.9381433955351921
14	0.7095656327812718	0.7095656327812718	0.9123714156278405
15	0.7199221199925434	0.7199221199925434	0.928090716258503
16	0.7071082845979172	0.7071082845979172	0.9145550503198707
17	0.7044891839496803	0.7044891839496803	0.9092145520990541
18	0.6947753934430027	0.6947753934430027	0.9029497946797399
19	0.7407496824595962	0.7407496824595962	0.931932429431384
20	0.7030119135792038	0.7030119135792038	0.9137091113319196
21	0.69357092666295	0.69357092666295	0.9083745997002972
22	0.7120759905280769	0.7120759905280769	0.9184556502778486
23	0.6865695044735969	0.6865695044735969	0.9017355110529907
24	0.7133274483336208	0.7133274483336208	0.9217406256890792
25	0.704652701636819	0.704652701636819	0.9210442107378476
26	0.6798942067627304	0.6798942067627304	0.8946496508417993
27	0.6792712167789803	0.6792712167789803	0.8926758872409277
28	0.698911200035144	0.698911200035144	0.9164261963083133
29	0.6799918133694305	0.6799918133694305	0.8950410806715587
30	0.6784212040396486	0.6784212040396486	0.8929969328505173
31	0.677591923299998	0.677591923299998	0.8919616535042234
32	0.6785882506972967	0.6785882506972967	0.8930874331642693
33	0.6772812833507025	0.6772812833507025	0.8917782174685663
34	0.6799709261009002	0.6799709261009002	0.8948522637590838
35	0.6803080697566124	0.6803080697566124	0.8943765473388512
36	0.6777321510624064	0.6777321510624064	0.8918169381490898
37	0.67742005357316	0.67742005357316	0.8919962507980017
38	0.6777998542862484	0.6777998542862484	0.8921170677806715
39	0.6780101959811506	0.6780101959811506	0.8925121104905436
40	0.6785139323370495	0.6785139323370495	0.8928881654689181
41	0.6789504464160363	0.6789504464160363	0.8934812204490957
42	0.6796724467724667	0.6796724467724667	0.894397849837448
43	0.6803839890366004	0.6803839890366004	0.8952385049120474
