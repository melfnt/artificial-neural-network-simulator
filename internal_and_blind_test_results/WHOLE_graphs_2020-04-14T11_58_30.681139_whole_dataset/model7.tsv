# MLPRegressor
# dataset: whole_dataset
# date: 2020-04-14T11_58_30.682554
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0017164735753597117, "batch_size": 5, "activation": "logistic", "learning_rate": "linear", "learning_rate_init": 0.051375660832639905, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.5586182890198031, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	1.298363527949993	1.298363527949993	1.3061323746200912
2	2.0469175012158156	2.0469175012158156	1.6832420001956145
3	1.3316041377169292	1.3316041377169292	1.302633548434341
4	1.2897231305977443	1.2897231305977443	1.31437316630496
5	1.237340642347894	1.237340642347894	1.272642731287341
6	1.0758463298989516	1.0758463298989516	1.1792201537132028
7	1.029066971447823	1.029066971447823	1.1655774452040342
8	1.3099342388562114	1.3099342388562114	1.2731293555752066
9	1.077138500868746	1.077138500868746	1.154953599841295
10	0.8883580173826396	0.8883580173826396	1.0371842650098535
11	0.9221123468747638	0.9221123468747638	1.0612929652323144
12	1.2726085868501589	1.2726085868501589	1.3277999231694748
13	0.8449879849283559	0.8449879849283559	1.005474787391253
14	1.177052864333016	1.177052864333016	1.2136745376161908
15	0.8989648486060297	0.8989648486060297	1.0414561570129452
16	1.0228112132573017	1.0228112132573017	1.1564054680634952
17	0.9454200634391313	0.9454200634391313	1.0862740436553073
18	0.8742066652861905	0.8742066652861905	1.01455580757573
19	0.8377561176210424	0.8377561176210424	1.0113813142243726
20	0.9595472501075508	0.9595472501075508	1.1418263145703296
21	0.8365573087489342	0.8365573087489342	1.0661110282828556
22	0.837609733916145	0.837609733916145	1.0458401814444294
23	0.8621704378140019	0.8621704378140019	1.0499170708758905
24	1.235766302526861	1.235766302526861	1.3640352689782576
25	0.7574798826743422	0.7574798826743422	0.951427166342113
26	0.8618162705359853	0.8618162705359853	1.0233867231826261
27	0.759399036551503	0.759399036551503	0.949418395606208
28	0.7360368727288402	0.7360368727288402	0.9449722953322706
29	0.8068627912153044	0.8068627912153044	0.9848622680837076
30	0.9451337541592508	0.9451337541592508	1.1056835807534788
31	1.17177708605651	1.17177708605651	1.2555993045726805
32	0.7023499950730363	0.7023499950730363	0.9239317595308805
33	0.7539339203872562	0.7539339203872562	0.9778624741906066
34	0.7536950671045423	0.7536950671045423	0.952981312827535
35	0.8452793843670172	0.8452793843670172	1.0252053201409395
36	0.7656945395494471	0.7656945395494471	0.9858522973872579
37	0.7487632462499149	0.7487632462499149	0.9612999953172514
38	0.9871287365893477	0.9871287365893477	1.126222184624277
39	0.8018482235258718	0.8018482235258718	0.9653765917454941
40	0.7351330010374025	0.7351330010374025	0.9533476534122268
41	0.707829089328725	0.707829089328725	0.9252717539614992
42	0.7578486879545769	0.7578486879545769	0.9581811485807104
