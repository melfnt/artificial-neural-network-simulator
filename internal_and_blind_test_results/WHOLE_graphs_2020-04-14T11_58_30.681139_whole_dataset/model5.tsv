# MLPRegressor
# dataset: whole_dataset
# date: 2020-04-14T11_58_30.682236
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0008463654654544185, "batch_size": 1, "activation": "logistic", "learning_rate": "adaptive", "learning_rate_init": 0.07968904898581924, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.2954139368874502, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_uniform", "weights_init_value": 0.6682284952429505}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	1.9129521261083087	1.9129521261083087	1.547097123020594
2	2.130457493790503	2.130457493790503	1.679596732309805
3	1.9798257027066237	1.9798257027066237	1.69074231826674
4	1.4446762132191548	1.4446762132191548	1.3568733543449967
5	1.2187923262937537	1.2187923262937537	1.2269416186162803
6	1.1910034363061726	1.1910034363061726	1.2094227787150407
7	1.3615020859260878	1.3615020859260878	1.2976681080561006
8	1.007989078321791	1.007989078321791	1.135836605545931
9	1.5333533912356752	1.5333533912356752	1.537106129033308
10	1.0226489681117386	1.0226489681117386	1.1198770260066166
11	0.8129580826261883	0.8129580826261883	1.0173824985062387
12	0.7847533915554579	0.7847533915554579	0.9615981556379573
13	0.8112578919498303	0.8112578919498303	1.0185651819820192
14	0.88355880013473	0.88355880013473	1.0588315292494292
15	0.7250693876053359	0.7250693876053359	0.9231877883835561
16	0.7140249626786691	0.7140249626786691	0.9097861601912102
17	0.701935190691152	0.701935190691152	0.9114333527105872
18	0.6909423734726843	0.6909423734726843	0.9006818659514999
19	0.8511680220598387	0.8511680220598387	0.9966842903079639
20	0.7315373995834397	0.7315373995834397	0.9626768076953031
21	0.6629663298189005	0.6629663298189005	0.8836588684761353
22	0.6809581617104788	0.6809581617104788	0.8971821337646361
23	0.6688960991273056	0.6688960991273056	0.8891682789697877
24	0.6573395062211614	0.6573395062211614	0.878546793144532
25	0.6457880034868372	0.6457880034868372	0.8638296373823323
26	0.6448533195450683	0.6448533195450683	0.8617789791023995
27	0.6483007619605161	0.6483007619605161	0.8682442006609952
28	0.6812438926956127	0.6812438926956127	0.8960165829980508
29	0.6411065993670576	0.6411065993670576	0.8602744811654928
30	0.6422425349748901	0.6422425349748901	0.8629498665541144
31	0.6471061253563838	0.6471061253563838	0.8656484272204839
32	0.641175596921967	0.641175596921967	0.8620507152661128
33	0.6399800052521448	0.6399800052521448	0.861148706705412
34	0.6406979015995096	0.6406979015995096	0.8623346933572207
35	0.6409279526967975	0.6409279526967975	0.863958088335598
36	0.6402754192740485	0.6402754192740485	0.8622584830114699
37	0.6406265883772184	0.6406265883772184	0.8632677951740808
38	0.6410365256694679	0.6410365256694679	0.8638637262080546
39	0.6412626869195445	0.6412626869195445	0.8633924968775633
40	0.6420594372000057	0.6420594372000057	0.8638998929685736
41	0.6426728689567863	0.6426728689567863	0.8648029137259686
42	0.6437560037648348	0.6437560037648348	0.866207260949292
43	0.6447991718309496	0.6447991718309496	0.8674983399146936
