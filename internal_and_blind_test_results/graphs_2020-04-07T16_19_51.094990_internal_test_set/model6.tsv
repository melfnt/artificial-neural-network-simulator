# MLPRegressor
# dataset: internal_test_set
# date: 2020-04-07T16_19_51.096364
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0009044205421256557, "batch_size": 1, "activation": "logistic", "learning_rate": "adaptive", "learning_rate_init": 0.06205633095090332, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.01510303444629194, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	2.318410987391557	2.255127119269441	1.7637454882019283
2	1.6199520505999012	1.4686860287837462	1.3658580213397675
3	1.410782853185234	1.4074029955187533	1.3782609090009423
4	2.1235602229636084	1.9521344106035334	1.7907490946864602
5	1.8459710118459816	1.6764681183529064	1.563162140499762
6	1.3338368130868865	1.3183280371558224	1.340234655177798
7	1.1276067460595718	1.1264831850730013	1.1881424646760739
8	1.2205824969900998	1.2560202401571803	1.278708484746834
9	0.8303043569692681	0.8921458142248245	0.9894650770434124
10	0.7885478924936791	0.8893656581548218	0.9845599661898847
11	0.9404283583277062	1.072585433491979	1.145498119427403
12	1.0401311439560719	1.1536887882030065	1.189116171005893
13	0.7985224620928079	0.9791949680956235	1.0892001212009115
14	0.7007201758938383	0.8316430010558519	0.9912140793860293
15	0.695344753772217	0.8428325534974992	0.9658209006363553
16	0.6618625080554712	0.8346509756061693	0.9679750359798502
17	0.6694730054738744	0.870692712408951	1.0225941833847165
18	0.6512326759064955	0.8292755535746031	0.9434921905577073
19	0.6368915673754804	0.8151478715140313	0.9497034673640583
20	0.6533931377768356	0.870797753950881	0.9841325213366708
21	0.6660687809097849	0.8618087672815958	0.9550720652041864
22	0.6051214740578413	0.7930925385456139	0.9501655344765206
23	0.6016218706379881	0.7914075243025258	0.9371690972842713
24	0.5947477142403964	0.8081452085999086	0.9376203289738526
25	0.5930783649646969	0.8039385210956449	0.9638853459246751
26	0.6290734169488773	0.8627771289149689	0.9723111292255413
27	0.6400946140757559	0.8659172922036987	0.967804861372734
28	0.5802277005146913	0.8073819210455211	0.9741121571081043
29	0.5994861461170324	0.8238748048406378	0.9425912338325858
30	0.5691042545726891	0.7972038687053467	0.955495062864971
31	0.5588135093433669	0.7899057668778718	0.9438772667575629
32	0.5540509192867202	0.7830032136085363	0.9348343204225603
33	0.5734114305100197	0.8056403263333904	0.9641674498086836
34	0.5648540938470161	0.7971744235639212	0.9403027094876929
35	0.5551468493774133	0.7904693384913678	0.9307807935443192
36	0.5543194037149233	0.7853569157025378	0.9294009128714974
37	0.5487880985463172	0.7857372983076488	0.9365501774901367
38	0.5586701669320295	0.7884385057652459	0.9336209104208998
39	0.5470817624757347	0.7828262714388848	0.9359459867160335
40	0.5569292650046379	0.7954072537184441	0.9566227542630462
41	0.5481766744306522	0.7855873711650838	0.9346670949216905
42	0.5476362069493731	0.7843568009997332	0.9381051798878843
43	0.5479832707806592	0.7841934852537951	0.9379450142291141
44	0.5480727944092232	0.7814867334143117	0.9331307838719248
45	0.5483160926912988	0.7817137076940267	0.9357298822067222
46	0.5489704362597349	0.781895765203441	0.9369629559843291
47	0.5497823155314786	0.7819232793349432	0.9381740945317449
48	0.5507330621709763	0.7825445489710456	0.9398001679718812
49	0.551713362294134	0.7829133206584753	0.941009560321796
