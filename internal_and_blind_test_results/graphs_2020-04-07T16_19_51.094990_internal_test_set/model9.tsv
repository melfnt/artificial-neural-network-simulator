# MLPRegressor
# dataset: internal_test_set
# date: 2020-04-07T16_19_51.096576
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0016753169392290158, "batch_size": 5, "activation": "logistic", "learning_rate": "constant", "learning_rate_init": 0.06569622348675933, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.5544087332459164, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	2.1519171165234665	2.0620779017462745	1.5962463242277736
2	1.3251249984028854	1.1712009129361787	1.2748865081123015
3	1.8560784380183937	1.814161615826091	1.6266174429888065
4	1.2965172432946852	1.2497014232526207	1.2474802067861628
5	1.10395928840458	1.1334037333800973	1.2020955963723174
6	1.0137158180417045	1.016206837602804	1.1615094639017252
7	1.0210424755564358	1.1008764880982185	1.182112493584341
8	1.500392697203496	1.6519665626381392	1.4665097941041654
9	1.6525904309683632	1.7583932909626727	1.5857243376872434
10	2.470573602863011	2.54627911283469	1.837972611151487
11	1.2579589178336923	1.366961583292443	1.38515669279098
12	0.8848025956850392	1.0136118602686062	1.1229221249257237
13	1.217883491871936	1.409123538968777	1.346021972423442
14	1.1511345453674229	1.2410928860359298	1.184377163662389
15	0.9990532764656926	1.1636577865660895	1.1860013904729492
16	1.0222086489508426	1.1854025539319168	1.206526456273588
17	0.8848355330443867	1.0387931366666918	1.1573251655773427
18	0.9056774566956611	1.0571581352965664	1.1358275312237778
19	1.766782610266291	2.0056217493202313	1.735360346002465
20	0.9780319997449417	1.1306381287513598	1.1289305757090358
21	0.762589809913368	0.947658722496213	1.0372621455931217
22	0.8783672380197226	1.0835266801725985	1.1770403553147037
23	1.0057930438504843	1.1925785855878337	1.2676826336724187
24	1.1703311497221534	1.3677875785635143	1.3480502424479663
25	1.0179989009077455	1.1919126517317438	1.2171427454293626
26	0.7520104601193078	0.9959129652239599	1.1131154041028057
27	0.7401051085319423	0.9561538048538605	1.0515594358636537
28	0.6942497761678712	0.9155910105803164	1.035813349671193
29	0.7675489108148258	0.9591256810644386	1.0866663508000944
30	0.6855953457498242	0.9056385057784662	1.0178554653987977
31	0.7221161694591233	0.9511486639929905	1.0410653147465387
32	0.7001940544958651	0.9508995742516821	1.0826224209994475
33	0.7736915899490947	1.0089445750175963	1.0862243563479894
34	0.7352068691264783	0.9765492855493103	1.0878345603838024
35	0.6922266498352937	0.9254121660941719	1.0504433750087594
36	0.7659750423163135	1.0223736712213565	1.1327744501459076
37	0.896803238601196	1.1747880847529897	1.215675514250766
38	0.7517251152699789	0.9862434861723003	1.071511767295468
39	0.6982672947216052	0.9587761267216599	1.0335944946815507
40	0.8666292272742115	1.1082710077402596	1.101574502785672
