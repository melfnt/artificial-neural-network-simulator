# MLPRegressor
# dataset: internal_test_set
# date: 2020-04-07T16_19_51.096302
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0008463654654544185, "batch_size": 1, "activation": "logistic", "learning_rate": "adaptive", "learning_rate_init": 0.07968904898581924, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.2954139368874502, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_uniform", "weights_init_value": 0.6682284952429505}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	3.2792230202189594	3.0279942175181422	2.151317051355939
2	8.057388447877079	8.084949334139868	3.7529971753337583
3	2.1259339212974613	1.9082413535998217	1.651163947136509
4	2.0162563570371983	1.9852316527647105	1.718367407135675
5	3.059746765699808	2.90512473331864	1.9683847319952608
6	2.4111426037197283	2.232076565018388	1.7927826991242448
7	1.0876579685512642	1.1992676552247201	1.286945594751353
8	0.9690290961951851	1.0635096355750622	1.161939981501905
9	1.0223014197618396	1.1449769014343931	1.2398763826830828
10	0.8700473894205559	0.9927802624376337	1.0892063370535185
11	0.9563765313194716	1.0817659427581146	1.1988248604307592
12	0.8667322760512212	1.041872253871897	1.1102573660768438
13	0.8838469524830953	0.972013404541727	1.0949491338039605
14	0.9300742253306424	1.0536360217915293	1.1408049670665066
15	0.7794672526193417	0.9347468073312162	1.026958770579364
16	0.7625535117620633	0.9266500637686051	1.0490406628140918
17	0.723636356164392	1.003133338136073	1.10497702698888
18	0.6688410598264368	0.9014152487398617	1.0084711020992794
19	0.8199920935447188	1.0440354486065098	1.158181694695956
20	0.7339779088575538	0.9984049220449374	1.0503135954365839
21	0.6295535390140029	0.914740032176222	1.0100573427783597
22	0.6917884959288358	0.9527325545983931	1.04442150441063
23	0.6548070343233932	0.9344251075460988	1.064739206675617
24	0.5989576679456684	0.8788450883590144	0.9811329538749486
25	0.6455495198026333	0.9305456820041822	1.0279021673104172
26	0.5877543726677821	0.8930640935027852	1.0068719557431947
27	0.5882159975523548	0.8836075322405114	0.9845731914684499
28	0.5831792363078061	0.878153177607322	0.9917849650356463
29	0.5824000554671922	0.8773194303656532	0.982511711208299
30	0.5825271775424057	0.8749501190305717	0.990804366210164
31	0.589299435845514	0.8761642216833053	1.0059109510074271
32	0.5847762458952163	0.8697026846672884	0.998554529147351
33	0.5686308856912652	0.8668493205412682	0.9818328904655788
34	0.5699678389768037	0.8659371507003651	0.9815910583260834
35	0.5781548928991824	0.8748633300571884	1.005955163874947
36	0.5666528802822279	0.8649816813228867	0.9886799251372802
37	0.566636118379605	0.8634950530105638	0.9841394907681716
38	0.5682067418611768	0.8656048275233371	0.9891155618724297
39	0.5638120109312224	0.8610180274819426	0.9822526758196191
40	0.5640791017670634	0.8605626306625856	0.9813790559908123
41	0.5656224091296052	0.8623363113746321	0.985206365425055
42	0.5650387676739259	0.8613164555543025	0.9823019820527388
43	0.564524297344732	0.8599877540483054	0.9821165740177084
44	0.5648420821643932	0.8593963074338147	0.9814745537448208
45	0.5653406994889106	0.8590378929674494	0.9809944432401846
46	0.5660820243189909	0.8590963280051834	0.9822100038341703
47	0.5667033710179057	0.8588204627657248	0.9825961346717441
48	0.5678802119560118	0.8591640673928171	0.9840606204596195
49	0.5690497211841931	0.8594524727271547	0.9853400793227046
