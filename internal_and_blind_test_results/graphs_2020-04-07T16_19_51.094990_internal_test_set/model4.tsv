# MLPRegressor
# dataset: internal_test_set
# date: 2020-04-07T16_19_51.096234
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0002188148237404819, "batch_size": 1, "activation": "logistic", "learning_rate": "constant", "learning_rate_init": 0.016437178740396977, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.483140617180181, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	1.4679689824833373	1.319450486870151	1.3252998782624015
2	2.376463919609972	2.375083365564647	1.8599594783807296
3	1.5372553787129086	1.4942582316293551	1.4341498608487142
4	1.2672572822182862	1.2037909860031026	1.2759147197148613
5	1.4846023271013082	1.529454166890174	1.4392882548161716
6	1.0224771553757421	1.1065805622726184	1.1532066152769855
7	1.464667243287405	1.4788201363619458	1.4873018848975348
8	1.1215145544652445	1.1844659251189935	1.2551972301910737
9	0.9281216782229227	1.0411128277697579	1.1068344658272717
10	1.0383739663777987	1.2090593258243294	1.2046483907172405
11	1.2375967720723389	1.338869502684704	1.3647735218497536
12	0.8531629310547123	1.034076563592626	1.0984707751127092
13	0.84921171434777	1.0054319871649708	1.0889953084561566
14	1.260546455360639	1.447887907883333	1.3805956555567158
15	0.8649834354734218	1.0190167486024488	1.095037201590611
16	0.8094505521615611	0.9863833367403083	1.0612600631002989
17	1.0019623734218384	1.2225854236901326	1.2305409147003852
18	0.948138449845852	1.1441991926575505	1.2005873721590103
19	0.7358393014442036	0.941435217745989	1.0384632933744797
20	0.7661066355981336	0.950100447694073	1.0566912631587757
21	0.8006895657269109	1.0067115739196955	1.1003574744362663
22	0.6940605140212175	0.9318414443382672	1.0433678890729912
23	1.188247103734857	1.4083655823253045	1.3686467117630665
24	0.723072922404899	0.9587666088229081	1.0374306531621562
25	0.65135964171277	0.9128760582039166	1.028765555352956
26	0.7422166932621562	0.9903951628455229	1.0792957276789192
27	0.8297611264028412	1.0419729717751178	1.0853491934769164
28	0.7710446980041177	1.039158112643522	1.1179020998594005
29	0.9086642713633336	1.1401983556339153	1.1459473667682145
30	0.76311887715096	0.9732376763815764	1.0496817507717706
31	0.6956662212123543	0.9740885452178925	1.044509924993125
32	0.7137693939716158	0.9777436875879763	1.0554062360545942
33	0.6651400777645795	0.9659773498491375	1.0636790712700028
34	0.6789442839686913	1.072260794571228	1.123356128695674
35	0.9552403983962762	1.2816449765415951	1.2358958693888376
