# MLPRegressor
# dataset: whole_dataset
# date: 2020-04-26T10_41_46.444551
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0005951915361345095, "batch_size": 1, "activation": "logistic", "learning_rate": "adaptive", "learning_rate_init": 0.054980020763198, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.8050419419933234, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)	train_accuracy(euclidean)
1	1.7072897948462218	1.7072897948462218	1.530921949429065	1.530921949429065
2	1.9434836717086503	1.9434836717086503	1.6425227725958893	1.6425227725958893
3	1.8209228975839746	1.8209228975839746	1.5501313691791618	1.5501313691791618
4	1.6930122265215406	1.6930122265215406	1.554431786871052	1.554431786871052
5	1.0423959695271439	1.0423959695271439	1.1245248842760371	1.1245248842760371
6	1.043209648889494	1.043209648889494	1.1279212248105257	1.1279212248105257
7	0.9338643026103501	0.9338643026103501	1.0787468497988582	1.0787468497988582
8	0.8677700895063098	0.8677700895063098	1.0451404095780197	1.0451404095780197
9	0.9525572831787871	0.9525572831787871	1.136834357577806	1.136834357577806
10	0.8243083384771924	0.8243083384771924	0.9906713971462926	0.9906713971462926
11	0.8292452088001653	0.8292452088001653	1.0025219650818449	1.0025219650818449
12	0.8597885265363464	0.8597885265363464	1.015560504961782	1.015560504961782
13	0.9018526849414249	0.9018526849414249	1.0614272933338365	1.0614272933338365
14	0.7536816447799333	0.7536816447799333	0.9419072460731219	0.9419072460731219
15	0.7337119658582918	0.7337119658582918	0.9504157760160952	0.9504157760160952
16	0.7955698084067766	0.7955698084067766	1.002617889064628	1.002617889064628
17	0.8215100025456764	0.8215100025456764	1.0278393338165548	1.0278393338165548
18	0.7212132940122898	0.7212132940122898	0.933876940503854	0.933876940503854
19	0.7055383487262848	0.7055383487262848	0.9257100108315617	0.9257100108315617
20	0.6570765657019287	0.6570765657019287	0.8772764896035946	0.8772764896035946
21	0.681394534704343	0.681394534704343	0.886022642320447	0.886022642320447
22	0.6406250483189816	0.6406250483189816	0.864457954167673	0.864457954167673
23	0.6422677620865193	0.6422677620865193	0.8646316978955781	0.8646316978955781
24	0.6373351625589738	0.6373351625589738	0.8648687922952979	0.8648687922952979
25	0.6859727175198103	0.6859727175198103	0.9195253199571564	0.9195253199571564
26	0.6788723297806729	0.6788723297806729	0.9036462377755842	0.9036462377755842
27	0.6091807441015871	0.6091807441015871	0.8436890440013529	0.8436890440013529
28	0.614082561666874	0.614082561666874	0.8469740465668064	0.8469740465668064
29	0.6061107326382937	0.6061107326382937	0.8389305988407333	0.8389305988407333
30	0.6369431132414696	0.6369431132414696	0.8755764149704921	0.8755764149704921
31	0.6093949013303206	0.6093949013303206	0.8461011588693231	0.8461011588693231
32	0.6098221319327038	0.6098221319327038	0.8465845950231903	0.8465845950231903
33	0.6124353541744822	0.6124353541744822	0.8524529728534885	0.8524529728534885
34	0.5988590260041247	0.5988590260041247	0.8382778139082481	0.8382778139082481
35	0.5978819953276291	0.5978819953276291	0.8350609121317034	0.8350609121317034
36	0.5966598357757043	0.5966598357757043	0.8344480983772493	0.8344480983772493
37	0.5955372302915728	0.5955372302915728	0.8316728658228151	0.8316728658228151
38	0.5964406501886689	0.5964406501886689	0.8348052296988457	0.8348052296988457
39	0.5942269999348246	0.5942269999348246	0.8320404975473891	0.8320404975473891
40	0.5950626472637627	0.5950626472637627	0.831785408858319	0.831785408858319
41	0.6051422810685928	0.6051422810685928	0.8427928435347835	0.8427928435347835
42	0.5940696459546477	0.5940696459546477	0.8308056788378305	0.8308056788378305
43	0.5937049755111201	0.5937049755111201	0.8308803808632611	0.8308803808632611
44	0.5939791354453098	0.5939791354453098	0.8318537567152445	0.8318537567152445
45	0.5950295332608381	0.5950295332608381	0.8333234274986798	0.8333234274986798
46	0.5940921017751113	0.5940921017751113	0.8313452039827103	0.8313452039827103
47	0.5943569043979268	0.5943569043979268	0.8322437966717843	0.8322437966717843
48	0.5946161425466742	0.5946161425466742	0.8320476884274217	0.8320476884274217
49	0.595031035252341	0.595031035252341	0.8324754941171303	0.8324754941171303
50	0.5954317104772241	0.5954317104772241	0.8331273065198779	0.8331273065198779
51	0.5958567544318342	0.5958567544318342	0.8337720126227564	0.8337720126227564
52	0.5966247774333365	0.5966247774333365	0.8348650171219744	0.8348650171219744
53	0.5973428027577546	0.5973428027577546	0.8359172769941545	0.8359172769941545
