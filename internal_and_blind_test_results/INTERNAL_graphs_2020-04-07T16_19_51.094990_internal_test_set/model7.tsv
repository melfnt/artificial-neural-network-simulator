# MLPRegressor
# dataset: internal_test_set
# date: 2020-04-07T16_19_51.096426
# parameters: {"hidden_layer_sizes": [50, 50], "alpha": 0.0017164735753597117, "batch_size": 5, "activation": "logistic", "learning_rate": "linear", "learning_rate_init": 0.051375660832639905, "power_t": 0.5, "max_iter": 200, "shuffle": true, "random_state": 42, "tol": 0.0001, "verbose": false, "warm_start": false, "momentum": 0.5586182890198031, "nesterovs_momentum": true, "early_stopping": false, "validation_fraction": 0.1, "n_iter_no_change": 10, "weights_init_fun": "random_normal", "weights_init_value": 0.7}
epoch	train_loss(squared)	valid_loss(squared)	valid_accuracy(euclidean)
1	1.498060190567331	1.3676005156133682	1.3700790405600325
2	1.6746165168736353	1.5840534153066155	1.4067086723223756
3	1.329040909604219	1.2906950174435865	1.2983722027947637
4	1.2380287259170986	1.2084526899048327	1.2661571579652084
5	1.0106120568267005	1.088871212791919	1.185845552438323
6	1.1374961021432852	1.2342675976245003	1.265086189488202
7	1.0783798229093173	1.206415790155025	1.2329364770026323
8	1.1338752441617577	1.2671892294806213	1.2031053007595083
9	1.1140666635159184	1.1933277892821224	1.2080570906855905
10	1.0046075157068	1.0632449688378145	1.1676040529370333
11	1.09383643924531	1.2155988013834271	1.2012440900254548
12	1.1706322163312934	1.2504678617805929	1.3169629980134798
13	0.8783339440462982	1.0346146679901687	1.1078333008386376
14	0.9641717951842259	1.085273079431718	1.129820363300357
15	0.8411351188714994	0.9905656170325584	1.0822468487578503
16	0.8751929341379625	0.9981894236678696	1.0769964311390898
17	0.8288439824047806	0.9425477188725645	1.065312731701229
18	0.9277977523631084	1.0280248445902238	1.1652813500631063
19	0.8682818160651248	1.0246578395587078	1.0923104166783832
20	1.0389004883133026	1.176448820113178	1.132537992719949
21	0.8544023770432254	0.9762398867866723	1.0801294800621495
22	0.875609193803909	1.0441633670113524	1.1207726427985638
23	1.3821969156470748	1.5560202068149984	1.3649210333846782
24	0.8530933246987066	0.989150842686081	1.0624896889723165
25	0.9291570200248339	1.1080946322096679	1.1367511945029791
26	1.002561320655041	1.166617230381888	1.1497484316781996
27	0.8539828955125507	1.0069957157648526	1.1352802547475553
